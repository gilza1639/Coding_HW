"""
Задание 2.
Предложить варианты оптимизации и доказать (наглядно, кодом) их эффективность
"""

'''
Предисловие, почему я использую модуль у которого в основе лежит getsizeof, которым пользоваться обычно не принято (даже вы показывали asizeof)

Функция sys.getsizeof возвращает размер переданного ей обьекта, этот размер не включает в себя сложные структуры классов и т.д.
Функция pympler.asizeof - рекурсивно ищет всё вложенние поля и элементы, и отображает общий размер обьекта

Через удобный


Теперь почему я выбрад именно эти пункты: вы формируете свою программу курсов и наверняка у многих из дз возьмете для следующих курсов неплохие примеры
И это самые просты примеры, которые точно поймет большинство:

например из (# Вар_1: Умный Python) можно сделать вывод, что для хранения повторяющихся данных лучше использовать list , чем dict или deque 
(про недостаток deque в task_1.py)

Также для вас оставил строку 93, с помощью нее можно объяснить студентам чем tuple превосходит list в плане памяти
И в качестве демонстрации, например, привести пример, что все пустые tuple весят 0 и что все пустые tuple имеют один и тот же id присвоения
'''




# как я понимаю, варианты нужно брать не из урока (а иначе смысла нет)


from pysize import get_size
import random

# Вар_1: Умный Python



some_list_len_100 = [random.randint(1, 100) for el in range(1000)]
some_list_len_1000 = [random.randint(1, 100) for el in range(100000)]

result_of_list = get_size([])
result_1 = get_size(some_list_len_100)
result_2 = get_size(some_list_len_1000)

print(f'result for list []; get_size([]) : {result_of_list}')
print(f'some_list_len_100: {result_1}')
print(f'some_list_len_1000: {result_2}')
print(f'Результат второго вычисления в ({result_2} / {result_1}) = {result_2/result_1} раз больше')
print(f'Но исходя из логики, первый список длинной в {len(some_list_len_100)}, а второй {len(some_list_len_1000)}, следовательно их разница по рамеру должна быть в ({len(some_list_len_1000)} / {len(some_list_len_100)}) = {len(some_list_len_1000)/len(some_list_len_100)} раз (не считая размера list)')

'''
result for list []; get_size([]) : 28
some_list_len_100: 1376
some_list_len_1000: 5908
Результат второго вычисления в (5908 / 1376) = 4.2936046511627906 раз больше
Но исходя из логики, первый список длинной в 100, а второй 1000, следовательно их разница по рамеру должна быть в (1000 / 100) = 10.0 раз (не считая размера list)

'''


print('\n'*5)

# Python оптимизирует список, поскольку видит в нем одинаковые элементы, хотя они находятся в хаотичном порядке



# Вар_2 - правильное использование


# Предположим, что вам нужно поятонно удерживать в памяти какой-то список и постоянно брать из него примеры
# допустим на random.choice() вы подаете массив данных на 1000000 строк, чтобы он постоянно выбирал случайное
# и вероятнее всего вы сохраните этот список через [], потому что это намного привычнее, чем неизменяемый кортеж ()


some_list_len_1000 = [random.randint(1, 100) for el in range(1000000)]


result_2 = get_size(some_list_len_1000)
print(f'some_list_len_1000: {result_2}')

some_tuple_len_1000 = tuple(some_list_len_1000)

result_2_tuple = get_size(some_tuple_len_1000)
print(f'some_tuple_len_1000: {result_2_tuple}')

'''
some_list_len_1000: 4350128
some_tuple_len_1000: 4001420
'''
print('\n'*5)
# Кортежи работают чуть лучше в основном из-за своей неизменяемости
# хорошо это объяснил Raymond Hettinger на stackoverflow
# https://stackoverflow.com/questions/68630/are-tuples-more-efficient-than-lists-in-python/22140115#22140115











































































































